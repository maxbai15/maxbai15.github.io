# Capstone Project - AI Yearbook Digitization

## Research

## Description of Final Project Choice, Why It Was Chosen, and What a Successful Project Would Do  

For my capstone project, I chose to help design and build an **automated data extraction and analysis tool** that helps collect and organize large sets of raw information from past yearbooks at Charlotte Latin and turn it into a preservable digital database. The goal of the project is to reduce the amount of manual work required when trying to access data from decades of yearbooks and creating a digital database to preserve the information throughout time.

I chose this project because it allows me to combine the theoretical coding I have been learning to real-world applications. This project enables me to use my abilties to create a useful tool for the community my school and community.

A successful version of this project would:
- Automatically extract relevant data from past yearbook pdfs
- Clean and standardize the extracted data
- Output the results in a structured format ready for analysis
- Increase efficiency by reducding human manual labor
- Create a searchable AI database with the extracted data

Ultimately, success for this project means creating a tool that saves time, improves accuracy, and can realistically be continously used in future years to make an efficient way to continue adding data to a digital searchable database.

## INSTRUCTIONS SECTION  

## Tools Used 

### Software Tools:
- **Python** â€“ Core language used to build the extraction and processing logic
- **VS Code** â€“ Code editor for writing and debugging scripts
- **GitHub** â€“ Version control and file management
- **Terminal / Command Line** â€“ Running scripts and testing outputs

### Digital Tools:
- Screenshot tools for documentation
- File explorers for managing datasets

### Machine Settings:
- Python version: 3.x
- Libraries used: standard libraries for file handling and data processing

---

## Files Included  
**(Instructions Row 15)**

The following digital files are included as part of this project:
- Python scripts for data extraction
- Python scripts for data cleaning and formatting
- Sample input datasets
- Output files showing processed data
- Documentation files explaining usage and workflow

All files are organized into clearly labeled folders to make navigation and reuse easier.

---

## DETAILED WORKFLOW OF DATA EXTRACTION  
*(Screenshots should be inserted at each step below)*

### Step 1: Input Data Identification  
The first step is identifying the structure of the raw data. This includes determining file type, formatting inconsistencies, and what information is relevant.

ðŸ“¸ **Screenshot Placeholder:** Raw input data

---

### Step 2: Extraction Logic  
A Python script scans the input data line by line, using conditional logic to locate relevant values while ignoring unnecessary information.

ðŸ“¸ **Screenshot Placeholder:** Extraction script code

---

### Step 3: Data Cleaning  
Once extracted, the data is cleaned by removing duplicates, correcting formatting issues, and standardizing values.

ðŸ“¸ **Screenshot Placeholder:** Cleaned data output

---

### Step 4: Structured Output  
The cleaned data is saved into a structured format that can be easily analyzed or reused.

ðŸ“¸ **Screenshot Placeholder:** Final output file

---

## DOCUMENTATION OF LEARNING  
### (Rubric Row 18)

---

## January Focus: Specific Problem & Coding Tool Development

In January, I focused on improving a specific weakness in my project: **handling inconsistent data formats**. Early versions of the tool worked well only when data followed a predictable structure. Real-world datasets did not behave this way, causing frequent errors.

To address this, I developed a more flexible parsing system that:
- Detects patterns instead of relying on fixed positions
- Uses conditional logic to handle missing or malformed data
- Logs errors instead of crashing the program

This improvement significantly increased the reliability of the tool.

---

## Struggles, Challenges, and How I Overcame Them

One of my biggest struggles was debugging logic errors that did not produce obvious crashes but resulted in incorrect outputs. At first, it was frustrating because the program appeared to run correctly while silently producing flawed data.

I overcame this by:
- Breaking the script into smaller, testable sections
- Printing intermediate values to verify assumptions
- Using version control to safely experiment without losing progress

Another major challenge was time management. I underestimated how long it would take to properly document the process. Once I realized this, I adjusted my workflow to document as I worked rather than waiting until the end.

These challenges forced me to slow down, think more critically, and develop better habits as both a programmer and project manager.

---

## Reflection (Ongoing)

This project taught me that large projects are less about technical difficulty and more about **organization, persistence, and adaptability**. I learned that mistakes are not setbacks but signals that something needs to be redesigned or clarified. Moving forward, I would like to expand this tool into a more user-friendly application with a graphical interface and broader dataset support.

---

**TOTAL SECTIONS COMPLETED FOR THIS SUBMISSION:**
- Research: Rows 4 & 5  
- Instructions: Rows 14 & 15  
- Documentation of Learning: Row 18  
